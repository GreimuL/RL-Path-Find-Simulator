# RL-Path-Find-Simulator
Path Find Simulator using Reinforcement learning

Q러닝을 사용한 길찾기 시뮬레이터 입니다.
## 영상
[![Trailer](https://img.youtube.com/vi/43Tv3OWXR9U/0.jpg)](https://youtu.be/43Tv3OWXR9U)
## 만든 이유  
강화학습 공부를 하다가 Q러닝파트를 보는데,  
에피소드가 끝나지 않았음에도, 각 스텝마다 판단하여 학습하는 Q러닝의 방법이 인상적이었습니다.  
그래서 재밌어보여서 만들어 봤습니다.
## 전제 조건
- 출발지점은 좌상단, 도착지점은 우하단 
- 최적의 path = 최단 거리 path 
- 업데이트 할 때 사용하는 식  
Q(S,A) = Q(S,A) + alpha * (reward + max(Q(S',A')) - Q(S,A))  
reward = -1, alpha = 0.1
## 사용 방법
1. 맵 사이즈를 설정하고 Create를 누릅니다. (Default Size: 5 X 5)  
2. 벽을 세우고 싶은 위치의 버튼을 눌러둡니다.  
    - 주의 사항
        - 도착 지점까지의 path가 존재하지 않는다면, step 단위로 움직일때는 상관없지만, 만약 에피소드 단위로 진행하게 된다면 무한 루프에 걸리게 됩니다.  
3. Set 버튼을 눌러서 맵을 적용시킵니다.  
4. Next Step이나 Play Episode를 눌러서 학습시킵니다.  
Play Episode에서 진행할 에피소드의 개수를 설정할 수 있습니다. (Default: 1000)  

## 추가 정보

- 맵 타일의 화살표는 에이전트가 생각하는 그 타일에서의 최적의 방향입니다.  
화살표를 보고 학습 상황을 알 수 있습니다.  
- 랜덤 확률을 결정하는 epsilon이 존재하기 때문에 꼭 최적 방향으로만 움직이지는 않습니다.  
- epsilon은 직접 설정 가능합니다.  (다만 0에서 1사이의 값이어야 합니다.)  
학습이 충분이 되었다 싶으면 epsilon을 0으로 만들어서 최적의 길로 가는 에이전트를 확인해볼 수 있습니다.  
- epsilon을 Set 한 순간 epsilon은 reset하기 전 까진, annealing 되지 않고 고정됩니다.  
- 보통 500번이상의 에피소드정도 진행해야 최단 path를 찾을 정도로 학습이 됩니다.  
- 에이전트가 많이 방문하지 못한 타일은 엉뚱한 방향의 화살표가 있을 수 있습니다.  
많이 방문하지 못한 탓에 학습이 제대로 이루어지지 않아서 생기는 현상입니다.  
보통 최단거리와 관련없는 위치의 타일들에서 자주 일어납니다.  
- epsilon 값을 높게 주고 에피소드를 여러번 돌리면 학습속도는 느리지만, 구석 타일 까지도 잘 학습되는 것을 볼 수 있습니다.